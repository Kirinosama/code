1.对于这种最优策略的期望DP 我们一般都是从后往前推
枚举每次挑战 枚举此时的状态 枚举宝物是哪种
如果当前的宝物可以吃 就在吃与不吃的后继状态中选择最大值加到当前状态上
如果当前的宝物不能吃 只能选择不吃的后继状态加到当前状态上
最后输出f[1][0]就是答案

即 已知所有结果状态的答案 反推最优策略

2.
